{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install scikit-optimize lightgbm imbalanced-learn\n",
        "\n",
        "import time\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\n",
        "from skopt import BayesSearchCV\n",
        "from skopt.space import Real, Integer\n",
        "import lightgbm as lgb\n",
        "from imblearn.combine import SMOTEENN\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Gerar dataset fictício\n",
        "from sklearn.datasets import make_classification\n",
        "pd.set_option('display.max_columns', None)\n",
        "df = pd.read_csv('https://drive.google.com/uc?export=download&id=1Lma-amQu0WjV-PCAr2LOe377H99z4BoR')\n",
        "\n",
        "X = df.drop('y', axis=1)\n",
        "y = df['y']\n",
        "\n",
        "\n",
        "# Dividir o dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "smote = SMOTEENN(random_state=42)\n",
        "X_train, y_train = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "# Definir o espaço de busca dos hiperparâmetros\n",
        "search_space = {\n",
        "    'n_estimators': Integer(100, 500),\n",
        "    'learning_rate': Real(0.01, 0.2, 'log-uniform'),\n",
        "    'max_depth': Integer(3, 10),\n",
        "    'num_leaves': Integer(20, 50),\n",
        "    'min_child_samples': Integer(5, 30),\n",
        "    'subsample': Real(0.6, 1.0),\n",
        "    'colsample_bytree': Real(0.6, 1.0)\n",
        "}\n",
        "\n",
        "# Inicializar o modelo\n",
        "model = lgb.LGBMClassifier()\n",
        "\n",
        "# Inicializar o BayesSearchCV\n",
        "bayes_search = BayesSearchCV(estimator=model, search_spaces=search_space, n_iter=50, cv=3, n_jobs=-1, verbose=2, random_state=42)\n",
        "\n",
        "# Medir o tempo de execução\n",
        "start_time = time.time()\n",
        "bayes_search.fit(X_train, y_train)\n",
        "end_time = time.time()\n",
        "\n",
        "# Calcular o tempo total de execução\n",
        "total_time = end_time - start_time\n",
        "print(f'Tempo total de execução: {total_time / 60:.2f} minutos')\n",
        "\n",
        "# Obtendo os melhores hiperparâmetros\n",
        "best_params = bayes_search.best_params_\n",
        "print(f'Melhores hiperparâmetros: {best_params}')\n",
        "\n",
        "# Avaliando o modelo com os melhores hiperparâmetros\n",
        "best_model = bayes_search.best_estimator_\n",
        "\n",
        "# Prever no conjunto de teste\n",
        "y_pred_best = best_model.predict(X_test)\n",
        "y_prob_best = best_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Calculando diferentes métricas de desempenho\n",
        "accuracy_best = accuracy_score(y_test, y_pred_best)\n",
        "precision_best = precision_score(y_test, y_pred_best)\n",
        "recall_best = recall_score(y_test, y_pred_best)\n",
        "f1_best = f1_score(y_test, y_pred_best)\n",
        "roc_auc_best = roc_auc_score(y_test, y_prob_best)\n",
        "\n",
        "print(f'Acurácia: {accuracy_best:.2f}')\n",
        "print(f'Precisão: {precision_best:.2f}')\n",
        "print(f'Revocação: {recall_best:.2f}')\n",
        "print(f'F1-score: {f1_best:.2f}')\n",
        "print(f'AUC-ROC: {roc_auc_best:.2f}')\n",
        "#Melhores hiperparâmetros: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.055719924550648614), ('max_depth', 8), ('min_child_samples', 5), ('n_estimators', 219), ('num_leaves', 50), ('subsample', 0.6)])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDvPXvMdI8Dd",
        "outputId": "d4584429-f897-4a84-f0ec-3fa05c55f703"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-optimize\n",
            "  Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: lightgbm in /usr/local/lib/python3.10/dist-packages (4.4.0)\n",
            "Requirement already satisfied: imbalanced-learn in /usr/local/lib/python3.10/dist-packages (0.12.3)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.4.2)\n",
            "Collecting pyaml>=16.9 (from scikit-optimize)\n",
            "  Downloading pyaml-24.7.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: numpy>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.26.4)\n",
            "Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.13.1)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (1.3.2)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from scikit-optimize) (24.1)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from imbalanced-learn) (3.5.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from pyaml>=16.9->scikit-optimize) (6.0.1)\n",
            "Downloading scikit_optimize-0.10.2-py2.py3-none-any.whl (107 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.8/107.8 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyaml-24.7.0-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-24.7.0 scikit-optimize-0.10.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/dask/dataframe/__init__.py:42: FutureWarning: \n",
            "Dask dataframe query planning is disabled because dask-expr is not installed.\n",
            "\n",
            "You can install it with `pip install dask[dataframe]` or `conda install dask`.\n",
            "This will raise in a future version.\n",
            "\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
            "[LightGBM] [Info] Number of positive: 25178, number of negative: 22144\n",
            "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.015867 seconds.\n",
            "You can set `force_row_wise=true` to remove the overhead.\n",
            "And if memory is not enough, you can set `force_col_wise=true`.\n",
            "[LightGBM] [Info] Total Bins 2857\n",
            "[LightGBM] [Info] Number of data points in the train set: 47322, number of used features: 34\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.532057 -> initscore=0.128404\n",
            "[LightGBM] [Info] Start training from score 0.128404\n",
            "Tempo total de execução: 7.17 minutos\n",
            "Melhores hiperparâmetros: OrderedDict([('colsample_bytree', 1.0), ('learning_rate', 0.055719924550648614), ('max_depth', 8), ('min_child_samples', 5), ('n_estimators', 219), ('num_leaves', 50), ('subsample', 0.6)])\n",
            "Acurácia: 0.87\n",
            "Precisão: 0.45\n",
            "Revocação: 0.76\n",
            "F1-score: 0.57\n",
            "AUC-ROC: 0.91\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "joblib.dump(best_model, 'best_model_lgbm.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9fD83xbQMDPF",
        "outputId": "aa423e91-89f1-421f-c374-cff10e436ea2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['best_model_lgbm.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}